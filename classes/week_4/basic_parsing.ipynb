{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')\n",
    "for tree in t:\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "  \"\"\")\n",
    "sent = [\"I\", \"shot\", \"an\", \"elephant\", \"in\", \"my\", \"pajamas\"]\n",
    "parser = nltk.ChartParser(grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.generate import generate\n",
    "for sentence in generate(grammar, n=10):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I' | DT NN | P\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my' |'DT'\n",
    "    N -> 'elephant' | 'pajamas'|'NN'\n",
    "    V -> 'shot'|'VBP'|'VBD'\n",
    "    P -> 'in'|'PRP$'| 'PRP'| 'IN'\n",
    "    \n",
    "\n",
    "  \"\"\")\n",
    "sent = [\"I\", \"shot\", \"an\", \"elephant\", \"in\", \"my\", \"sweatshirt\"]\n",
    "try:\n",
    "    parser = nltk.ChartParser(grammar)\n",
    "    for tree in parser.parse(sent):\n",
    "        print(tree)\n",
    "except:\n",
    "    print(\"error parsing the sentence\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "input = \"I shot him\"\n",
    "tokens = treebank_tokenizer.tokenize(input)\n",
    "print(tokens)\n",
    "\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(pos_tags)\n",
    "pos_only = [tag[1] for tag in pos_tags]\n",
    "print(pos_only)\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "for tree in parser.parse(pos_only):\n",
    "        print(tree)\n",
    "    \n",
    "print(\"tse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "#nlp = StanfordCoreNLP(r'/products/corenlp/stanford-corenlp-full-2018-02-27')\n",
    "nlp = StanfordCoreNLP('http://localhost', port=9000)\n",
    "sentence = 'The ship has sailed.'\n",
    "constituency = nlp.parse(sentence)\n",
    "print('Constituency Parsing:', constituency)\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constituency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import *\n",
    "Tree.fromstring(constituency).pretty_print()\n",
    "const_tree = Tree.fromstring(constituency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodes(parent):\n",
    "    for node in parent:\n",
    "        if type(node) is Tree:\n",
    "            if node.label() == \"ROOT\":\n",
    "                print(\"======== Sentence =========\")\n",
    "                print(\"Sentence:\", \" \".join(node.leaves()))\n",
    "            else:\n",
    "                print(\"Label:\", node.label())\n",
    "                print(\"Leaves:\", node.leaves())\n",
    "\n",
    "            getNodes(node)\n",
    "        else:\n",
    "            print(\"Word:\", node)\n",
    "getNodes(const_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
